{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c53fa172",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D as KerasConv2D, MaxPooling2D as KerasMaxPooling2D, Flatten as KerasFlatten, Dropout as KerasDropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Assuming your custom layers are in a 'layers' directory relative to your notebook\n",
    "# Make sure the paths in your uploaded files (e.g., from .layer import Layer) are resolvable\n",
    "# For example, if 'layers' is a package, it might need an __init__.py\n",
    "# For simplicity here, we'll assume the .py files are directly accessible in a 'layers' folder.\n",
    "\n",
    "# Import your custom layers\n",
    "from layers.conv2d import Conv2D as CustomConv2D # Assuming you have this file\n",
    "from layers.pooling import MaxPooling2D as CustomMaxPooling2D\n",
    "from layers.flatten import Flatten as CustomFlatten\n",
    "from layers.dropout import Dropout as CustomDropout\n",
    "\n",
    "# Helper to print comparison results\n",
    "def print_outputs_and_comparison(keras_out, custom_out, layer_name):\n",
    "    print(f\"\\n--- {layer_name} ---\")\n",
    "    print(f\"Keras output shape: {keras_out.shape}\")\n",
    "    print(f\"Custom output shape: {custom_out.shape}\")\n",
    "    print(\"Keras output sample:\\n\", keras_out.flatten()[:8])\n",
    "    print(\"Custom output sample:\\n\", custom_out.flatten()[:8])\n",
    "    if keras_out.shape == custom_out.shape and np.allclose(keras_out, custom_out, atol=1e-6):\n",
    "        print(f\"✅ Outputs for {layer_name} are identical or very close!\")\n",
    "    else:\n",
    "        print(f\"⚠️ Outputs for {layer_name} are DIFFERENT.\")\n",
    "        diff = np.abs(keras_out - custom_out)\n",
    "        print(f\"   Max absolute difference: {np.max(diff)}\")\n",
    "        # print(f\"   Mean absolute difference: {np.mean(diff)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afdc3d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Attempting to Reload Modules ---\n",
      "Successfully reloaded: layers.layer (as LayerBase)\n",
      "Successfully reloaded: layers.conv2d (as Conv2D)\n",
      "Module sequential not in sys.modules. Will attempt fresh import.\n",
      "Successfully reloaded: layers.pooling (as MaxPooling2D)\n",
      "Successfully reloaded: layers.flatten (as Flatten)\n",
      "Module layers.dense not in sys.modules. Will attempt fresh import.\n",
      "Successfully reloaded: layers.dropout (as Dropout)\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import sys\n",
    "\n",
    "# --- Modules to Reload ---\n",
    "module_paths = {\n",
    "    \"LayerBase\": \"layers.layer\",\n",
    "    \"Conv2D\": \"layers.conv2d\",\n",
    "    \"Sequential\": \"sequential\",\n",
    "    \"MaxPooling2D\": \"layers.pooling\",\n",
    "    \"Flatten\": \"layers.flatten\",\n",
    "    \"Dense\": \"layers.dense\",\n",
    "    \"Dropout\": \"layers.dropout\",\n",
    "}\n",
    "\n",
    "print(\"--- Attempting to Reload Modules ---\")\n",
    "for logical_name, module_path_str in module_paths.items():\n",
    "    if module_path_str in sys.modules:\n",
    "        try:\n",
    "            # Get the actual module object from sys.modules\n",
    "            module_to_reload = sys.modules[module_path_str]\n",
    "            importlib.reload(module_to_reload)\n",
    "            print(f\"Successfully reloaded: {module_path_str} (as {logical_name})\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reloading {module_path_str}: {e}\")\n",
    "    else:\n",
    "        print(f\"Module {module_path_str} not in sys.modules. Will attempt fresh import.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e901b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input data shape: (2, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "# Input data configuration\n",
    "batch_size = 2\n",
    "img_height = 28\n",
    "img_width = 28\n",
    "channels = 3 # Using 3 channels for a more general Conv2D test\n",
    "\n",
    "# Generate random input data\n",
    "# Adding a high value to ensure weights have a noticeable effect\n",
    "sample_input_data = np.random.rand(batch_size, img_height, img_width, channels).astype(np.float32) * 10\n",
    "\n",
    "print(f\"Sample input data shape: {sample_input_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cea3f015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model and custom layers initialized.\n"
     ]
    }
   ],
   "source": [
    "# Keras Model\n",
    "keras_input = Input(shape=(img_height, img_width, channels))\n",
    "keras_conv = KerasConv2D(filters=4, kernel_size=(3, 3), padding='valid', activation='relu', name=\"conv2d_1\")(keras_input)\n",
    "keras_pool = KerasMaxPooling2D(pool_size=(2, 2), name=\"maxpool_1\")(keras_conv)\n",
    "keras_flatten = KerasFlatten(name=\"flatten_1\")(keras_pool)\n",
    "keras_dropout = KerasDropout(rate=0.5, name=\"dropout_1\")(keras_flatten) # Rate doesn't matter for inference\n",
    "keras_model = Model(inputs=keras_input, outputs=[keras_conv, keras_pool, keras_flatten, keras_dropout])\n",
    "\n",
    "# Get intermediate outputs from Keras model for comparison\n",
    "keras_conv_out_model = Model(inputs=keras_input, outputs=keras_conv)\n",
    "keras_pool_out_model = Model(inputs=keras_input, outputs=keras_pool)\n",
    "keras_flatten_out_model = Model(inputs=keras_input, outputs=keras_flatten)\n",
    "keras_dropout_out_model = Model(inputs=keras_input, outputs=keras_dropout)\n",
    "\n",
    "\n",
    "# Custom Layers Instantiation\n",
    "# Ensure parameters match Keras layers\n",
    "custom_conv = CustomConv2D(filters=4, kernel_size=(3,3), padding='valid', activation='relu')\n",
    "custom_pool = CustomMaxPooling2D(pool_size=(2, 2), padding='valid') # Assuming 'valid' is default or handled\n",
    "custom_flatten = CustomFlatten()\n",
    "custom_dropout = CustomDropout() # Dropout rate is irrelevant for inference\n",
    "\n",
    "print(\"Keras model and custom layers initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3a5a674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
      "Loaded weights for Conv2D. Kernel shape: (3, 3, 3, 4), Bias shape: (4,)\n",
      "Pooling has no trainable weights — skipping\n",
      "Called load_keras_weights for MaxPooling2D (no weights).\n",
      "Flatten has no trainable weights — skipping\n",
      "Called load_keras_weights for Flatten (no weights).\n",
      "Dropout has no trainable weights — skipping\n",
      "Called load_keras_weights for Dropout (no weights).\n"
     ]
    }
   ],
   "source": [
    "# It's good practice to build the model or run a dummy input to ensure weights are created\n",
    "_ = keras_model.predict(sample_input_data)\n",
    "\n",
    "# --- Conv2D ---\n",
    "keras_conv_layer = keras_model.get_layer(\"conv2d_1\")\n",
    "conv_weights = keras_conv_layer.get_weights() # [kernel, bias]\n",
    "if hasattr(custom_conv, 'load_keras_weights'):\n",
    "    # Assuming CustomConv2D.load_keras_weights expects [kernel, bias]\n",
    "    custom_conv.load_keras_weights(conv_weights)\n",
    "    print(f\"Loaded weights for Conv2D. Kernel shape: {conv_weights[0].shape}, Bias shape: {conv_weights[1].shape}\")\n",
    "else:\n",
    "    print(\"⚠️ CustomConv2D does not have load_keras_weights method. Skipping weight loading for Conv2D.\")\n",
    "\n",
    "\n",
    "# --- MaxPooling2D ---\n",
    "# MaxPooling2D has no trainable weights\n",
    "if hasattr(custom_pool, 'load_keras_weights'):\n",
    "    custom_pool.load_keras_weights([]) # Pass empty list or handle accordingly\n",
    "    print(\"Called load_keras_weights for MaxPooling2D (no weights).\")\n",
    "else:\n",
    "    # This is fine as per your pooling.py which doesn't have load_keras_weights\n",
    "    print(\"CustomMaxPooling2D does not have load_keras_weights method (expected for pooling).\")\n",
    "\n",
    "\n",
    "# --- Flatten ---\n",
    "# Flatten has no trainable weights\n",
    "if hasattr(custom_flatten, 'load_keras_weights'):\n",
    "    custom_flatten.load_keras_weights([])\n",
    "    print(\"Called load_keras_weights for Flatten (no weights).\")\n",
    "else:\n",
    "    # This is fine as per your flatten.py which does have it\n",
    "    print(\"⚠️ CustomFlatten does not have load_keras_weights method. Ensure this is intended.\")\n",
    "\n",
    "\n",
    "# --- Dropout ---\n",
    "# Dropout has no trainable weights\n",
    "if hasattr(custom_dropout, 'load_keras_weights'):\n",
    "    custom_dropout.load_keras_weights([])\n",
    "    print(\"Called load_keras_weights for Dropout (no weights).\")\n",
    "else:\n",
    "    # This is fine as per your dropout.py which does have it\n",
    "    print(\"⚠️ CustomDropout does not have load_keras_weights method. Ensure this is intended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4201734d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
      "\n",
      "--- Conv2D ---\n",
      "Keras output shape: (2, 26, 26, 4)\n",
      "Custom output shape: (2, 26, 26, 4)\n",
      "Keras output sample:\n",
      " [1.1282748 0.        2.7675052 0.        2.5542336 0.        0.\n",
      " 0.       ]\n",
      "Custom output sample:\n",
      " [1.12827468 0.         2.76750469 0.         2.55423355 0.\n",
      " 0.         0.        ]\n",
      "✅ Outputs for Conv2D are identical or very close!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "\n",
      "--- MaxPooling2D ---\n",
      "Keras output shape: (2, 13, 13, 4)\n",
      "Custom output shape: (2, 13, 13, 4)\n",
      "Keras output sample:\n",
      " [3.1308131  0.         2.7675052  0.25489885 1.7260418  0.\n",
      " 3.969039   2.1871903 ]\n",
      "Custom output sample:\n",
      " [3.13081288 0.         2.76750469 0.25489867 1.72604144 0.\n",
      " 3.9690392  2.18719006]\n",
      "✅ Outputs for MaxPooling2D are identical or very close!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "\n",
      "--- Flatten ---\n",
      "Keras output shape: (2, 676)\n",
      "Custom output shape: (2, 676)\n",
      "Keras output sample:\n",
      " [3.1308131  0.         2.7675052  0.25489885 1.7260418  0.\n",
      " 3.969039   2.1871903 ]\n",
      "Custom output sample:\n",
      " [3.13081288 0.         2.76750469 0.25489867 1.72604144 0.\n",
      " 3.9690392  2.18719006]\n",
      "✅ Outputs for Flatten are identical or very close!\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\n",
      "--- Dropout ---\n",
      "Keras output shape: (2, 676)\n",
      "Custom output shape: (2, 676)\n",
      "Keras output sample:\n",
      " [3.1308131  0.         2.7675052  0.25489885 1.7260418  0.\n",
      " 3.969039   2.1871903 ]\n",
      "Custom output sample:\n",
      " [3.13081288 0.         2.76750469 0.25489867 1.72604144 0.\n",
      " 3.9690392  2.18719006]\n",
      "✅ Outputs for Dropout are identical or very close!\n"
     ]
    }
   ],
   "source": [
    "# --- Test Conv2D Layer ---\n",
    "try:\n",
    "    # Keras prediction\n",
    "    keras_conv_output = keras_conv_out_model.predict(sample_input_data)\n",
    "\n",
    "    # Custom prediction\n",
    "    # Assuming CustomConv2D has a forward method\n",
    "    custom_conv_output = custom_conv.forward(sample_input_data)\n",
    "    print_outputs_and_comparison(keras_conv_output, custom_conv_output, \"Conv2D\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during Conv2D test: {e}\")\n",
    "    keras_conv_output = None # Ensure variable exists for next step\n",
    "    custom_conv_output = None\n",
    "\n",
    "\n",
    "# --- Test MaxPooling2D Layer ---\n",
    "if custom_conv_output is not None: # Proceed only if previous layer output is valid\n",
    "    try:\n",
    "        # Keras prediction (output from previous Keras layer is input to next)\n",
    "        keras_pool_output = keras_pool_out_model.predict(sample_input_data) # Gets output after conv and pool\n",
    "\n",
    "        # Custom prediction (output from custom_conv is input here)\n",
    "        custom_pool_output = custom_pool.forward(custom_conv_output)\n",
    "        print_outputs_and_comparison(keras_pool_output, custom_pool_output, \"MaxPooling2D\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during MaxPooling2D test: {e}\")\n",
    "        keras_pool_output = None\n",
    "        custom_pool_output = None\n",
    "else:\n",
    "    print(\"\\nSkipping MaxPooling2D test due to previous layer failure.\")\n",
    "    keras_pool_output = None\n",
    "    custom_pool_output = None\n",
    "\n",
    "\n",
    "# --- Test Flatten Layer ---\n",
    "if custom_pool_output is not None: # Proceed only if previous layer output is valid\n",
    "    try:\n",
    "        # Keras prediction\n",
    "        keras_flatten_output = keras_flatten_out_model.predict(sample_input_data)\n",
    "\n",
    "        # Custom prediction\n",
    "        custom_flatten_output = custom_flatten.forward(custom_pool_output)\n",
    "        print_outputs_and_comparison(keras_flatten_output, custom_flatten_output, \"Flatten\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Flatten test: {e}\")\n",
    "        keras_flatten_output = None\n",
    "        custom_flatten_output = None\n",
    "else:\n",
    "    print(\"\\nSkipping Flatten test due to previous layer failure.\")\n",
    "    keras_flatten_output = None\n",
    "    custom_flatten_output = None\n",
    "\n",
    "# --- Test Dropout Layer ---\n",
    "if custom_flatten_output is not None: # Proceed only if previous layer output is valid\n",
    "    try:\n",
    "        # Keras prediction\n",
    "        # Note: Keras Dropout layer behaves as identity during inference (model.predict)\n",
    "        keras_dropout_output = keras_dropout_out_model.predict(sample_input_data)\n",
    "\n",
    "        # Custom prediction\n",
    "        # Your custom Dropout.forward(x) returns x, which is correct for inference\n",
    "        custom_dropout_output = custom_dropout.forward(custom_flatten_output)\n",
    "        print_outputs_and_comparison(keras_dropout_output, custom_dropout_output, \"Dropout\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Dropout test: {e}\")\n",
    "else:\n",
    "    print(\"\\nSkipping Dropout test due to previous layer failure.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
